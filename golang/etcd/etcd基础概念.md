etcd是一个分布式的k-v存储系统，用于共享配置和服务发现
etcd默认数据一更新就落盘持久化

## 特点
- watch机制
- mvcc多版本并发控制，因为有协同系统需要无锁操作
- 支持RESful风格的`HTTP + JSON`的api
- 支持`grpc`，支持`gateway`转化
- 支持`tls`安全认证

## 场景
- 一致性键值存储
- 配置管理
- 服务发现
- 分布式锁
- 主备选举

## raft
`raft`协议保证etcd的强一致性，客户端的写操作会先存储到etcd的`leader`节点上，然后再复制到集群中其他节点，以此保证集群中每个节点的数据都是一致的；每个节点都存储了完整的数据

## wal
预写式，数据在提交之前会先记录日志，`snaphot`是为了防止数据过多而进行的状态快照

## 请求流程
- 收到请求
- http server 网络层转发给存储模块
- 涉及到节点变更则交给raft模块进行冲裁和日志的记录，然后同步给其他节点
- 只有当半数以上的节点确认了节点状态的修改之后，才会进行数据的持久化

## 节点状态
etcd中的每个节点有3个角色，包括`leader`，`follower`，`candidate`，在任意时刻，每个节点的角色都可能发生变化；当节点启动的时候，就会创建并维持与集群中其他节点之间的连接，节点之间的通信需要通过网络来传递数据
- leader发送心跳包给follower，follower进行回复
- leader发送日志追加信息给follower
- leader发送snapshot给follower
- candidate发起选举，向其他节点发送投票请求
- follower将收到的写操作转发给leader

## 数据通道
etcd的消息是通过`protobuf`格式进行编码，传输方式有两种，包括`stream`和`pipeline`，这两种方式都是通过`http`方式进行的
### stream
用于处理数据量较少的消息，点对点之间维护http长连接，底层实现会维护两个goroutine，一个接收请求写入到`raft`模块，一个是从`raft`模块读数据然后写到请求
### pipeline
用于处理数据量大的消息，例如`snapshot`，这类大消息需要和小消息（例如心跳包）区分开，否则会阻塞心跳包，点对点之间维护短连接，可以进行并发发出多个消息

## 线性读和可串行读
- 线性读，即读请求需要读到最新已经提交的数据，不会读到旧数据
- 可串行读，可以从`follower`节点直接读数据，可能会读到旧数据


## etcd v3
- 使用`grpc+protobuf`代替`http+json`，效率更高
- 使用更加轻量级的基于租约lease的key自动过期机制
- watcher机制优化，v2版本是基于http长连接，v3版本是基于`http/2`的`server push`，并且对事件进行了多路复用的优化
- 支持事务和多版本并发控制


